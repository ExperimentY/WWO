import numpy as np
import math

def initialization(search_agents_no, dim, ub, lb):
    # Number of boundaries
    boundary_no = len(ub)

    if boundary_no == 1:
        positions = np.random.rand(search_agents_no, dim) * (ub - lb) + lb
    else:
        # If each variable has a different lb and ub
        positions = np.zeros((search_agents_no, dim))
        for i in range(dim):
            ub_i = ub[i]
            lb_i = lb[i]
            positions[:, i] = np.random.rand(search_agents_no) * (ub_i - lb_i) + lb_i

    return positions


def WWO(pop_size, tmax, ub, lb, dim, f):
    conv_curve = np.zeros(tmax)

    # Controlling parameters
    t = 0  # Function evaluation counter

    # Initialization
    x = initialization(pop_size, dim, ub, lb)  # Initialize the positions of crested porcupines

    # Evaluation
    fitness = np.zeros(pop_size)
    for i in range(pop_size):
        fitness[i] = f(x[i, :][np.newaxis, :])

    # Update the best-so-far solution
    gb_fit = x[np.argmin(fitness), :]
    gb_sol = fitness[np.argmin(fitness)]

    xp = x.copy()  # A new array to store the personal best position for each crested porcupine
    best_F = np.inf
    best_Sol = np.ones(dim) * np.inf

    # Optimization Process of CPO
    while t < tmax:
        for i in range(pop_size):
            ll = np.random.choice(range(pop_size), size=2, replace=False)

            if np.random.rand() < 1-t/tmax:  
                num = np.random.randint(low=1, high=dim)
                D = np.zeros(dim)
                D[np.random.choice(dim, num, replace=False)] = 1
                x[i, :] = (1 - D) * x[i, :] + D * (x[ll[1], :] + np.random.normal(loc=0.0, scale=10) * (x[ll[0], :] - x[ll[1], :]))
            else:
                if (t>=800) or (t%2==0 and t>200):
                    x[i, :] = best_Sol.copy() + np.random.normal(loc=0.0, scale=10) * (1 - t / 1000) * (x[ll[0], :] - x[ll[1], :])
                else:
                    x[i, :] = x[i, :].copy() + np.random.normal(loc=0.0, scale=10) * (1 - t / 1000) * (x[ll[0], :] - x[ll[1], :])

            for j in range(dim):
                if x[i, j] > ub[j]:
                    x[i, j] = lb[j] + np.random.rand() * (ub[j] - lb[j])
                elif x[i, j] < lb[j]:
                    x[i, j] = lb[j] + np.random.rand() * (ub[j] - lb[j])

            # Calculate the fitness value of the newly generated solution
            nf = f(x[i, :][np.newaxis, :])

            # Update Global & Personal best solution
            if fitness[i] < nf[0]:
                x[i, :] = xp[i, :]  # Update local best solution
            else:
                xp[i, :] = x[i, :]
                fitness[i] = nf[0]

            if fitness[i] < best_F:
                best_F = fitness[i]
                best_Sol = xp[i, :].copy()

        conv_curve[t] = best_F  # Simplification for single-objective case
        t += 1  # Move to the next generation

    return best_F, best_Sol, conv_curve
